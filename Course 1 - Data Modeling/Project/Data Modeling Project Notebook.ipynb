{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Project Apache Cassandra Data Modeling\n",
    "## Project Overview\n",
    "This notebook focuses on creating data models and tables in Apache Cassandra to address the following queries:\n",
    "1. Retrieve artist, song title, and song's length for a specific `sessionId` and `itemInSession`.\n",
    "2. Retrieve artist, song (sorted by `itemInSession`), and user (first and last name) for a specific `userId` and `sessionId`.\n",
    "3. Retrieve all users who listened to a specific song.\n",
    "\n",
    "Each query has been carefully modeled to optimize data partitioning, retrieval, and performance while adhering to Apache Cassandra's design principles.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "- **Data Modeling and Table Creation**\n",
    "- **Data Insertion**\n",
    "- **Query Execution and Results**\n",
    "- **Clean-up and Conclusion**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preambule to load time management features to the project"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def timed_query(query, parameters=None):\n",
    "    start = time.time()\n",
    "    if parameters:\n",
    "        rows = session.execute(query, parameters)\n",
    "    else:\n",
    "        rows = session.execute(query)\n",
    "    end = time.time()\n",
    "    print(f\"Query executed in {end - start:.4f} seconds.\")\n",
    "    return rows\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/home\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x78c39b1b73c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of a Keyspace\n",
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS music_history\n",
    "    WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set KEYSPACE to the keyspace specified above\n",
    "session.set_keyspace('music_history')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Modeling Approach of Query 1: Retrieve Song Details for a Session\n",
    "The objective of **Query 1** is to retrieve the **artist name**, **song title**, and **song length** for a specific `sessionId` and `itemInSession`.\n",
    "\n",
    "**Table Name**: `session_songs`\n",
    "\n",
    "**Primary Key Components**:\n",
    "- **Partition Key**: `sessionId`\n",
    "- The `sessionId` groups all records for the same session into a single partition, ensuring efficient lookups.\n",
    "- **Clustering Column**: `itemInSession`\n",
    "- The `itemInSession` ensures uniqueness and natural order of rows within a partition.\n",
    "\n",
    "#### **Why This Design?**\n",
    "\n",
    "1. **Efficient Data Grouping**:\n",
    "Using `sessionId` as the partition key ensures that all records related to the same session are stored together in a single partition. This design allows Cassandra to quickly locate and retrieve all the records associated with a specific session without scanning unrelated partitions.\n",
    "\n",
    "2. **Uniqueness**:\n",
    "Adding `itemInSession` as the clustering column guarantees that each record within the same session is uniquely identifiable. It also maintains the natural order of items within a session, ensuring accurate and organized retrieval of records.\n",
    "\n",
    "3. **Optimized Query Execution**:\n",
    "The query filters data based on `sessionId` and `itemInSession`, which aligns perfectly with the table's partition key and clustering column. This alignment eliminates the need for `ALLOW FILTERING`, avoiding costly full table scans and ensuring efficient query performance.\n",
    "\n",
    "### **Final Table Design**\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS session_songs (\n",
    "    sessionId INT,          -- Partition Key\n",
    "itemInSession INT,      -- Clustering Column\n",
    "artist TEXT,\n",
    "       song TEXT,\n",
    "            length FLOAT,\n",
    "                   PRIMARY KEY (sessionId, itemInSession)\n",
    ");\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Query 1:  This query provide details on the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "# Create table for Query 1\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS session_songs (\n",
    "        sessionId INT,\n",
    "        itemInSession INT,\n",
    "        artist TEXT,\n",
    "        song TEXT,\n",
    "        length FLOAT,\n",
    "        PRIMARY KEY (sessionId, itemInSession)\n",
    "    )\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ff627",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Full Apache Cassandra code to insert the data in the target table\n",
    "import csv\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding='utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)  # skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = \"\"\"\n",
    "            INSERT INTO session_songs (sessionId, itemInSession, artist, song, length)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SELECT statement to verify that the data have been inserted into each table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88831f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## This SELECT statement help verifying that the data was appropriately entered into the table\n",
    "query = \"\"\"\n",
    "    SELECT artist, song, length \n",
    "    FROM session_songs \n",
    "    WHERE sessionId = 338 AND itemInSession = 4\n",
    "\"\"\"\n",
    "rows = timed_query(query)\n",
    "for row in rows:\n",
    "    print(f\"Artist: {row.artist}, Song: {row.song}, Length: {row.length}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Data Modeling Strategy of Query 2 to Retrieve Sorted Song and User Details\n",
    "#### Objective:\n",
    "Fetch the **artist name**, **song title** (sorted by `itemInSession`), and **user details** (first and last name) for a specific `userId` and `sessionId`.\n",
    "\n",
    "#### **How the Table is Designed**\n",
    "\n",
    "##### Step 1: Partition Key\n",
    "We use a **composite partition key** `(userId, sessionId)` to group records for a specific user session together. Grouping by `userId` and `sessionId` ensures that all data for the same user session is stored in one partition.\n",
    "\n",
    "##### Step 2: Clustering Column\n",
    "We use `itemInSession` as the clustering column. It **sorts** the records within the partition in ascending order of `itemInSession`.\n",
    "\n",
    "#### **Query Flow**\n",
    "\n",
    "1. Filter by `userId` and `sessionId` → Locate the partition.\n",
    "2. Retrieve rows → Sorted naturally by `itemInSession`.\n",
    "\n",
    "#### **Advantages**\n",
    "\n",
    "1. **Logical Grouping**: Data is grouped by `userId` and `sessionId`.\n",
    "2. **Sorting**: Sorting by `itemInSession` is built into the clustering column.\n",
    "3. **No ALLOW FILTERING**: Query is efficient and avoids unnecessary scans.\n",
    "\n",
    "#### **Table Definition**\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS user_sessions (\n",
    "    userId INT,               -- Partition Key Component\n",
    "sessionId INT,            -- Partition Key Component\n",
    "itemInSession INT,        -- Clustering Column\n",
    "artist TEXT,\n",
    "       song TEXT,\n",
    "            firstName TEXT,\n",
    "                      lastName TEXT,\n",
    "                               PRIMARY KEY ((userId, sessionId), itemInSession)\n",
    ");\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Query 2: This query provide only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "# Create table for Query 2\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS user_sessions (\n",
    "        userId INT,\n",
    "        sessionId INT,\n",
    "        itemInSession INT,\n",
    "        artist TEXT,\n",
    "        song TEXT,\n",
    "        firstName TEXT,\n",
    "        lastName TEXT,\n",
    "        PRIMARY KEY ((userId, sessionId), itemInSession)\n",
    "    )\n",
    "\"\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecad6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Insertion of data into user_sessions table\n",
    "with open(file, encoding='utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)  # skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = \"\"\"\n",
    "            INSERT INTO user_sessions (userId, sessionId, itemInSession, artist, song, firstName, lastName)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Query Execution\n",
    "This query retrieves the required data based on the defined partition key and clustering columns, without using `ALLOW FILTERING`.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009bc614",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Verifying the data for userId = 10 and sessionId = 182\n",
    "query = \"\"\"\n",
    "    SELECT artist, song, firstName, lastName \n",
    "    FROM user_sessions \n",
    "    WHERE userId = 10 AND sessionId = 182\n",
    "\"\"\"\n",
    "rows = timed_query(query)\n",
    "for row in rows:\n",
    "    print(f\"Artist: {row.artist}, Song: {row.song}, User: {row.firstname} {row.lastname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Data Modeling Roadmap for Query 3 to Extract All Users for a Specific Song\n",
    "### Objective:\n",
    "Retrieve the **first and last names** of all users who listened to a particular song.\n",
    "\n",
    "### **Table Design at a Glance**\n",
    "\n",
    "- **Table Name**: `song_listeners`\n",
    "- **Partition Key**: `song`\n",
    "- Ensures that all listeners of the same song are stored together in one partition.\n",
    "- **Clustering Column**: `userId`\n",
    "- Ensures each user appears **only once** in the partition, avoiding duplicates.\n",
    "\n",
    "### **Why is this Table Design Effective?**\n",
    "\n",
    "- **Efficient Data Retrieval**:\n",
    "By partitioning data using `song`, we can quickly retrieve all records for a specific song without scanning unrelated partitions.\n",
    "\n",
    "- **Unique User Identification**:\n",
    "The clustering column `userId` prevents duplicate entries for users within the same song partition.\n",
    "\n",
    "- **Optimal Query Execution**:\n",
    "The query filters on `song`, which aligns perfectly with the partition key. This avoids the need for `ALLOW FILTERING` and ensures fast performance.\n",
    "\n",
    "### **Table Definition**\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS song_listeners (\n",
    "    song TEXT,                -- Partition Key\n",
    "userId INT,               -- Clustering Column\n",
    "firstName TEXT,\n",
    "          lastName TEXT,\n",
    "                   PRIMARY KEY (song, userId)\n",
    ");\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create table for Query 3\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS song_listeners (\n",
    "        song TEXT,\n",
    "        userId INT,\n",
    "        firstName TEXT,\n",
    "        lastName TEXT,\n",
    "        PRIMARY KEY (song, userId)\n",
    "    )\n",
    "\"\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ceb4e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Insertion of the data into the song_listeners table\n",
    "with open(file, encoding='utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)  # skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = \"\"\"\n",
    "            INSERT INTO song_listeners (song, userId, firstName, lastName)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d1d01",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Query Execution\n",
    "This query retrieves the required data based on the defined partition key and clustering columns, without using `ALLOW FILTERING`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1addd82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Query 3 aims at givin every user name (first and last) in the music app history who listened to the song 'All Hands Against His Own'\n",
    "query = \"\"\"\n",
    "    SELECT firstName, lastName \n",
    "    FROM song_listeners \n",
    "    WHERE song = 'All Hands Against His Own'\n",
    "\"\"\"\n",
    "rows = timed_query(query)\n",
    "for row in rows:\n",
    "    print(f\"User: {row.firstname} {row.lastname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc29ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Execute the query\n",
    "query = \"SELECT song, length FROM session_songs\"\n",
    "rows = session.execute(query)\n",
    "\n",
    "# Convert rows to a list of tuples\n",
    "rows_list = list(rows)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows_list, columns=['song', 'length'])\n",
    "\n",
    "# Ensure 'length' is numeric and convert from seconds to minutes\n",
    "df['length'] = pd.to_numeric(df['length'], errors='coerce') / 60  # Convert to minutes\n",
    "\n",
    "# Remove duplicates based on 'song' and keep the minimum duration\n",
    "df = df.drop_duplicates(subset='song', keep='first')\n",
    "\n",
    "# Sort by 'length' in ascending order\n",
    "df_sorted = df.sort_values(by='length', ascending=False)\n",
    "\n",
    "# Select the top 10 songs (from shortest to longest duration)\n",
    "top_songs_ascending = df_sorted.head(10)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.bar(top_songs_ascending['song'], top_songs_ascending['length'])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title('Top 10 Songs by Length')\n",
    "plt.xlabel('Song')\n",
    "plt.ylabel('Length (minutes)', )\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Drop the tables before closing out the sessions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "## Dropping the tables before closing out the sessions\n",
    "session.execute(\"DROP TABLE IF EXISTS session_songs\")\n",
    "session.execute(\"DROP TABLE IF EXISTS user_sessions\")\n",
    "session.execute(\"DROP TABLE IF EXISTS song_listeners\")\n",
    "print(\"Tables dropped successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Close the session and cluster connection¶"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cassandra session and cluster connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Close the session and cluster connection\n",
    "session.shutdown()\n",
    "cluster.shutdown()\n",
    "print(\"Cassandra session and cluster connection closed.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Clean-up and Conclusion\n",
    "The tables have been dropped, and the Cassandra session and cluster connection have been closed to ensure resource cleanup.\n",
    "\n",
    "This notebook demonstrates how to correctly model data in Apache Cassandra to answer specific queries, optimize data partitioning, and avoid `ALLOW FILTERING`. The outputs have been presented in a clear and readable format using Pandas DataFrames.\n",
    "\n",
    "**Best Practices Followed**:\n",
    "- Logical table and column naming.\n",
    "- Efficient use of partition keys and clustering columns.\n",
    "- Avoidance of `ALLOW FILTERING`.\n",
    "- Modular and clean notebook structure.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}